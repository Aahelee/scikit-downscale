{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-downscale: an open source Python package for scalable climate downscaling\n",
    "\n",
    "Joseph Hamman (jhamman@ucar.edu) and Julia Kent (jkent@ucar.edu)\n",
    "\n",
    "NCAR, Boulder, CO, USA\n",
    "\n",
    "ECAHM 2020 ID: 143\n",
    "\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "Climate data from Earth System Models (ESMs) are increasingly being used to study the impacts of climate change on a broad range of biogeophysical systems (forest fire, flood, fisheries, etc.) and human systems (water resources, power grids, etc.). Before this data can be used to study many of these systems, post-processing steps commonly referred to as bias correction and statistical downscaling must be performed. “Bias correction” is used to correct persistent biases in climate model output and “statistical downscaling” is used to increase the spatiotemporal resolution of the model output (i.e. from 1 deg to 1/16th deg grid boxes). For our purposes, we’ll refer to both parts as “downscaling”.\n",
    "\n",
    "In the past few decades, the applications community has developed a plethora of downscaling methods. Many of these methods are ad-hoc collections of processing routines while others target very specific applications. The proliferation of downscaling methods has left the climate applications community with an overwhelming body of research to sort through without much in the form of synthesis guilding method selection or applicability.\n",
    "\n",
    "Motivated by the pressing socio-environmental challenges of climate change – and with the learnings from previous downscaling efforts in mind – we have begun working on a community-centered open framework for climate downscaling: [scikit-downscale](https://scikit-downscale.readthedocs.io/en/latest/). We believe that the community will benefit from the presence of a well-designed open source downscaling toolbox with standard interfaces alongside a repository of benchmark data to test and evaluate new and existing downscaling methods.\n",
    "\n",
    "In this notebook, we provide an overview of the scikit-downscale project, detailing how it can be used to downscale a range of surface climate variables such as surface air temperature and precipitation. We also highlight how scikit-downscale framework is being used to compare exisiting methods and how it can be extended to support the development of new downscaling methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Insert some sort of figure here, probably showing a “typical” workflow]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Scikit-downscale\n",
    "Scikit-downscale is a new open source Python project. Within Scikit-downscale, we are been building a collection of new and existing downscaling methods within a common framework. Key features of Scikit-downscale are:\n",
    "\n",
    "- A high-level interface modeled after the popular _fit_ / _precict_ pattern found in many machine learning packages ([Scikit-learn](https://scikit-learn.org/stable/index.html), [Tensorflow](https://www.tensorflow.org/guide/keras), etc.),\n",
    "- Uses [Xarray](http://xarray.pydata.org/en/stable/) and [Pandas](https://pandas.pydata.org/) data structures and utilities for handling of labeled datasets,\n",
    "- Utilities for automatic parallelization of pointwisde downscaling models,\n",
    "- Common interface for pointwise and spatial (or global) downscaling models, and\n",
    "- Extensible, allowing the creation of new downscaling methods through composition.\n",
    "\n",
    "Scikit-downscale's source code is available on [GitHub](https://github.com/jhamman/scikit-downscale)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Pointwise Models\n",
    "We define pointwise methods are those that only use local information during the downscaling process. They can be often represented as a linear model and fit independently across the entire study domain. Examples of existing pointwise methods are:\n",
    "\n",
    "- BCSD_[Temperature, Precipitation]: Wood et al 2002\n",
    "- ARRM: Stoner et al 2012\n",
    "- (Hybrid) Delta Method\n",
    "- GARD: https://github.com/NCAR/GARD\n",
    "\n",
    "Because pointwise methods can be written as a stand-alone linear model, Scikit-downscale implements these models as a Scikit-learn [LinearModel](https://scikit-learn.org/stable/modules/linear_model.html) or [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html). By building directly on Scikit-learn, we inherit a well defined model API and the ability to interoperate with a robust ecosystem utilities for model evaluation and optimization (e.g. grid-search). Perhaps more importantly, this structure also allows us to compare methods at a high-level of granularity (single spatial point) before deploying them on large domain problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Begin interactive demo***\n",
    "\n",
    "From here forward in this notebook, we'll jump back and forth between Python and text cells to describe how scikit-downscale works.\n",
    "\n",
    "This first cell just imports some libraries and get's things setup for our analysis to come."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # sklearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "from utils import get_sample_data\n",
    "\n",
    "sns.set(style='darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've imported a few libraries, let's open a sample dataset from a single point in North America. We'll use this data to explore Scikit-downscale and its existing functionality. You'll notice there are two groups of data, `training` and `targets`. We will mostly use the `tmax` variable (daily maximum surface air temperature) going forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sample data\n",
    "training = get_sample_data('training')\n",
    "targets = get_sample_data('targets')\n",
    "\n",
    "# print a table of the training/targets data\n",
    "display(pd.concat({'training': training, 'targets': targets}, axis=1))\n",
    "\n",
    "# make a plot of the temperature and precipitation data\n",
    "fig, axes = plt.subplots(ncols=1, nrows=2, figsize=(8, 6), sharex=True)\n",
    "time_slice = slice('1990-01-01', '1990-12-31')\n",
    "\n",
    "# plot-temperature\n",
    "training[time_slice]['tmax'].plot(ax=axes[0], label='training')\n",
    "targets[time_slice]['tmax'].plot(ax=axes[0], label='targets')\n",
    "axes[0].legend()\n",
    "axes[0].set_ylabel('Temperature [C]')\n",
    "\n",
    "# plot-precipitation\n",
    "training[time_slice]['pcp'].plot(ax=axes[1])\n",
    "targets[time_slice]['pcp'].plot(ax=axes[1])\n",
    "_ = axes[1].set_ylabel('Precipitation [mm/day]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Models as cattle, not pets\n",
    "\n",
    "As we mentioned above, Scikit-downscale utilizes a similiar API to that of Scikit-learn for its pointwise models. This means we can build collections of models that may be quite different internally, but opperate the same at the API level. This is perhaps the most important feature of Scikit-downscale, the ability to test and compare arbitrary combinations of models under a common interface. \n",
    "\n",
    "In the cell below, we'll create nine different downscaling models, some from Scikit-downscale and some from Scikit-learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from skdownscale.pointwise_models import PureAnalog, AnalogRegression\n",
    "from skdownscale.pointwise_models import BcsdTemperature, BcsdPrecipitation\n",
    "\n",
    "\n",
    "models = {\n",
    "    'GARD: PureAnalog-best-1': PureAnalog(kind='best_analog', n_analogs=1),\n",
    "    'GARD: PureAnalog-sample-10': PureAnalog(kind='sample_analogs', n_analogs=10),\n",
    "    'GARD: PureAnalog-weight-10': PureAnalog(kind='weight_analogs', n_analogs=10),\n",
    "    'GARD: PureAnalog-weight-100': PureAnalog(kind='weight_analogs', n_analogs=100),\n",
    "    'GARD: PureAnalog-mean-10': PureAnalog(kind='mean_analogs', n_analogs=10),\n",
    "    'GARD: AnalogRegression-100': AnalogRegression(n_analogs=100),\n",
    "    'GARD: LinearRegression': LinearRegression(),\n",
    "    'BCSD: BcsdTemperature': BcsdTemperature(return_anoms=False),\n",
    "    'Sklearn: RandomForestRegressor': RandomForestRegressor(random_state=0)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've created a collection of models, we want to train the models on the same input data. We do this by looping through our dictionary of models and calling the `fit` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit/predict using the PureAnalog class\n",
    "train_slice = slice('1980-01-01', '1989-12-31')\n",
    "\n",
    "X_train = training[['tmax']][train_slice]\n",
    "y_train = targets[['tmax']][train_slice]\n",
    "\n",
    "\n",
    "for key, model in models.items():\n",
    "    model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like that, we fit nine downscaling models. Now we want to use those models to downscale/bias-correct our data. For the sake of easy comparison, we'll use a different part of the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_slice = slice('1990-01-01', '1999-12-31')\n",
    "X_predict = training[['tmax']][predict_slice]\n",
    "\n",
    "# store predicted results in this dataframe\n",
    "predict_df = pd.DataFrame(index = X_predict.index)\n",
    "\n",
    "for key, model in models.items():\n",
    "    predict_df[key] = model.predict(X_predict)\n",
    "\n",
    "# show a table of the predicted data\n",
    "display(predict_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's do some sample analysis on our predicted data. First, we'll look at a timeseries of all the downscaled timeseries for the first year of the prediction period. In the figure below, the `target` (truth) data is shown in black, the original (pre-correction) data is shown in grey, and each of the downscaled data timeseries is shown in a different color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 3.5))\n",
    "targets['tmax'][time_slice].plot(ax=ax, label='target', c='k', lw=1, alpha=0.75, legend=True, zorder=10)\n",
    "X_predict['tmax'][time_slice].plot(label='original', c='grey', ax=ax, alpha=0.75, legend=True)\n",
    "predict_df[time_slice].plot(ax=ax, lw=0.75)\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "_ = ax.set_ylabel('Temperature [C]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, its difficult to tell which of the nine downscaling methods performed best from our plot above. We may want to evaluate our predictions using a standard statistical score, such as $r^2$. Those results are easily computed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate r2\n",
    "score = (predict_df.corrwith(targets.tmax[predict_slice]) **2).sort_values().to_frame('r2_score')\n",
    "display(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of our downscaling methods seem to be doing fairly well. The timeseries and statistics above shows that all our methods are producing generally resonable results. However, we are often interested in how our models do at predicting extreme events. We can quickly look into those aspects of our results using the `qq` plots below. There you'll see that the models diverge in some interesting ways. For example, while the `LinearRegression` method has the highest $r^2$ score, it seems to have trouble capturing extreme heat events. Whereas many of the analog methods, as well as the `RandomForestREgressor`, perform much better on the tails of the distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import prob_plots\n",
    "\n",
    "fig = prob_plots(X_predict, targets['tmax'], predict_df[score.index.values], shape=(3, 3), figsize=(12, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we've shown how easy it is to fit, predict, and evaluate scikit-downscale models. The seemless interoperability of these models clearly facilitates a workflow that enables a deeper level of model evaluation that is otherwise possible in the downscaling world. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Tailor-made methods in a common framework\n",
    "\n",
    "In the section above, we showed how it is possible to use scikit-downscale to bias-correct a timeseries of daily maximum air temperature using an arbitrary collection of linear models. Some of those models were general machine learning methods (e.g. `LinearRegression` or `RandomForestRegressor`) while others were tailor-made methods developed specifically for downscaling (e.g. `BCSDTemperature`). In this section, we walk through how new pointwise methods can be added to the scikit-downscale framework, highlighting the Z-Score method along the way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Z-Score Method\n",
    "\n",
    "Z-Score bias correction is a good technique for target variables with Gaussian probability distributions, such as zonal wind speed.\n",
    "\n",
    "In essence the technique:\n",
    "\n",
    "1. Finds the mean  \n",
    "$$\\overline{x} = \\sum_{i=0}^N \\frac{x_i}{N}$$ \n",
    "and standard deviation \n",
    "$$\\sigma = \\sqrt{\\frac{\\sum_{i=0}^N |x_i - \\overline{x}|^2}{N-1}}$$ \n",
    "of target (measured) data and training (historical modeled) data. \n",
    "\n",
    "2. Compares the difference between the statistical values to produce a shift \n",
    "$$shift = \\overline{x_{target}} - \\overline{x_{training}}$$ \n",
    "and scale parameter \n",
    "$$scale = \\sigma_{target} \\div \\sigma_{training}$$ \n",
    "\n",
    "3. Applies these paramaters to the future model data to be corrected to get a new mean\n",
    "$$\\overline{x_{corrected}} = \\overline{x_{future}} + shift$$\n",
    "and new standard deviation\n",
    "$$\\sigma_{corrected} = \\sigma_{future} \\times scale$$\n",
    "\n",
    "4. Calculates the corrected values\n",
    "$$x_{corrected_{i}} = z_i \\times \\sigma_{corrected} + \\overline{x_{corrected}}$$\n",
    "from the future model's z-score values\n",
    "$$z_i = \\frac{x_i-\\overline{x}}{\\sigma}$$\n",
    "\n",
    "In practice, if the wind was on average 3 m/s faster on the first of July in the models compared to the measurements, we would adjust the modeled data for all July 1sts in the future modeled dataset to be 3 m/s faster. And similarly for scaling the standard deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Building the ZScoreRegressor Class\n",
    "\n",
    "Scikit-downscale's pointwise all implement Scikit-learn's `fit`/`predict` API. Each new downscaler must implement a minimum of three class methods: `__init__`, `fit`, `predict`. \n",
    "\n",
    "```python\n",
    "class AbstractDownscaler(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        ...\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        ...\n",
    "        return self\n",
    "    \n",
    "    def predict(X):\n",
    "        ...\n",
    "        return y_hat\n",
    "```\n",
    "\n",
    "Ommitting some of the complexity in the full implementation (which can be found in the [full implementation on GitHub](https://github.com/jhamman/scikit-downscale/blob/master/skdownscale/pointwise_models/zscore.py)), we demonstrate how the `ZScoreRegressor` was built:\n",
    "\n",
    "First, we define our `__init__` method, allowing users to specify specific options (in this case `window_width`):\n",
    "```python\n",
    "class ZScoreRegressor(object):\n",
    "    \n",
    "    def __init__(self, window_width=31):\n",
    "        self.window_width = window_width\n",
    "```\n",
    "\n",
    "Next, we define our `fit` method, \n",
    "\n",
    "```python\n",
    "    def fit(self, X, y):\n",
    "        X_mean, X_std = _calc_stats(X.squeeze(), self.window_width)\n",
    "        y_mean, y_std = _calc_stats(y.squeeze(), self.window_width)\n",
    "        \n",
    "        self.stats_dict_ = {\n",
    "            \"X_mean\": X_mean,\n",
    "            \"X_std\": X_std,\n",
    "            \"y_mean\": y_mean,\n",
    "            \"y_std\": y_std,\n",
    "        }\n",
    "\n",
    "        shift, scale = _get_params(X_mean, X_std, y_mean, y_std)\n",
    "\n",
    "        self.shift_ = shift\n",
    "        self.scale_ = scale\n",
    "        return self\n",
    "```\n",
    "\n",
    "Finally, we define our `predict` method,\n",
    "\n",
    "```python\n",
    "    def predict(self, X):\n",
    "\n",
    "        fut_mean, fut_std, fut_zscore = _get_fut_stats(X.squeeze(), self.window_width)\n",
    "        shift_expanded, scale_expanded = _expand_params(X.squeeze(), self.shift_, self.scale_)\n",
    "\n",
    "        fut_mean_corrected, fut_std_corrected = _correct_fut_stats(\n",
    "            fut_mean, fut_std, shift_expanded, scale_expanded\n",
    "        )\n",
    "\n",
    "        self.fut_stats_dict_ = {\n",
    "            \"meani\": fut_mean,\n",
    "            \"stdi\": fut_std,\n",
    "            \"meanf\": fut_mean_corrected,\n",
    "            \"stdf\": fut_std_corrected,\n",
    "        }\n",
    "\n",
    "        fut_corrected = (fut_zscore * fut_std_corrected) + fut_mean_corrected\n",
    "\n",
    "        return fut_corrected.to_frame(name)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skdownscale.pointwise_models import ZScoreRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a small historical dataset\n",
    "training = get_sample_data('wind-hist')\n",
    "target = get_sample_data('wind-obs')\n",
    "future = get_sample_data('wind-rcp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bias correction using ZScoreRegresssor\n",
    "zscore = ZScoreRegressor()\n",
    "zscore.fit(training, target)\n",
    "hist_stats = zscore.stats_dict_\n",
    "out = zscore.predict(future)\n",
    "fut_stats = zscore.fut_stats_dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the datasets\n",
    "labels = ['training', 'future', 'target', 'corrected']\n",
    "colors = {k: c for (k, c) in zip(labels, sns.color_palette(\"Paired\", n_colors=4))}\n",
    "\n",
    "alpha = 0.5\n",
    "\n",
    "time_target = pd.date_range('1980-01-01','1989-12-31', freq='D')\n",
    "time_training = time_target[~((time_target.month==2) & (time_target.day==29))]\n",
    "time_future = pd.date_range('1990-01-01','1999-12-31', freq='D')\n",
    "time_future = time_future[~((time_future.month==2) & (time_future.day==29))]\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(time_training,training.uas, label='training', alpha=alpha, c=colors['training'])\n",
    "plt.plot(time_target,target.uas, label='target', alpha=alpha, c=colors['target'])\n",
    "\n",
    "plt.plot(time_future,future.uas, label='future', alpha=alpha, c=colors['future'])\n",
    "plt.plot(time_future,out.uas, label='corrected', alpha=alpha, c=colors['corrected'])\n",
    "\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Eastward Near-Surface Wind (m s-1)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the zscore correction\n",
    "def gaus(mean, std, doy):\n",
    "    mu = mean[doy]\n",
    "    sigma = std[doy]\n",
    "\n",
    "    x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n",
    "    y = scipy.stats.norm.pdf(x, mu, sigma)\n",
    "    return x, y\n",
    "\n",
    "training_mean = zscore.stats_dict_['X_mean']\n",
    "training_std = zscore.stats_dict_['X_std']\n",
    "target_mean = zscore.stats_dict_['y_mean']\n",
    "target_std = zscore.stats_dict_['y_std']\n",
    "\n",
    "future_mean = fut_stats['meani']\n",
    "future_mean = future_mean.groupby(future_mean.index.dayofyear).mean()\n",
    "future_std = fut_stats['stdi']\n",
    "future_std = future_std.groupby(future_std.index.dayofyear).mean()\n",
    "corrected_mean = fut_stats['meanf']\n",
    "corrected_mean = corrected_mean.groupby(corrected_mean.index.dayofyear).mean()\n",
    "corrected_std = fut_stats['stdf']\n",
    "corrected_std = corrected_std.groupby(corrected_std.index.dayofyear).mean()\n",
    "\n",
    "doy=20\n",
    "plt.figure()\n",
    "x,y = gaus(training_mean, training_std, doy)\n",
    "plt.plot(x, y, c=colors['training'], label = 'training')\n",
    "x,y = gaus(target_mean, target_std, doy)\n",
    "plt.plot(x, y, c=colors['target'], label = 'target')\n",
    "x,y = gaus(future_mean, future_std, doy)\n",
    "plt.plot(x, y, c=colors['future'], label = 'future')\n",
    "x,y = gaus(corrected_mean, corrected_std, doy)\n",
    "plt.plot(x, y, c=colors['corrected'], label = 'corrected')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic Parallelization and Pipelines\n",
    "\n",
    "In the examples above, we have performed downscaling on sample data sourced from individual points. In many downscaling workflows, however, users will want to apply pointwise methods at all points in their study domain. For this use case, scikit-downscale provides a high-level wrapper class: `PointWiseDownscaler`.\n",
    "\n",
    "TODO: JJH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Models\n",
    "Spatial models is a second class of downscaling methods that use information from the full study domain to form relationships between observations and ESM data. Scikit-downscale implements these models as as SpatialDownscaler. Beyond providing fit and predict methods that accept Xarray objects, the internal layout of these methods is intentionally unspecified. We are currently working on wrapping a few popular spatial downscaling models such as:\n",
    "\n",
    "- [MACA: Multivariate Adaptive Constructed Analogs](http://www.climatologylab.org/maca.html), Abatzoglou and Brown (2012)\n",
    "- [LOCA: Localized Constructed Analogs](http://loca.ucsd.edu/), Pierce, Cayan, and Thrasher (2014)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Applications\n",
    "Its likely that one of the reasons we haven’t seen strong consensus develop around particularl downscaling methodologies is the abscense of widely available benchamrk applications to test methods against eachother. While Scikit-downscale will not solve this problem on its own, we hope the ability to implemnt downscaling applications within a common framework will enable a more robust benchmarking inititive that previously possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call for Participation\n",
    "The Scikit-downscale effort is just getting started. With the recent release of [CMIP6](https://www.wcrp-climate.org/wgcm-cmip/wgcm-cmip6), we expect a surge of interest in downscaled climate data. There are clear opportunities for involvement from climate impacts practicioneers, computer scientists with an interest in machine learning for climate applications, and climate scientists alike. Please reach out if you are interested in participating in any way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Abatzoglou J.T. and Brown T.J. A comparison of statistical downscaling methods suited for wildfire applications, International Journal of Climatology (2012), 32, 772-780\n",
    "2. Pierce, D. W., D. R. Cayan, and B. L. Thrasher, 2014: Statistical downscaling using Localized Constructed Analogs (LOCA). Journal of Hydrometeorology, volume 15, page 2558-2585\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
